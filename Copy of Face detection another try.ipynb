{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Face detection another try.ipynb","provenance":[{"file_id":"1wkdsw3rBgRH_SuMuTbdSmTynIpyoFKkS","timestamp":1627302034544}],"authorship_tag":"ABX9TyOwrVCg+PULWEVvHJ47LiD0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"p3BpJd92LkHk"},"source":["##Install Dependencies"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"la2nqa5ZLccp","executionInfo":{"status":"ok","timestamp":1627297630323,"user_tz":-300,"elapsed":35043,"user":{"displayName":"Afaq Saeed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gid4S9oyckVYLjntFyS9LKYBNOND0YkmrGkBqQ=s64","userId":"02893802679832682328"}},"outputId":"850ebcab-f9ee-4a7d-d444-6a9e5520ed47"},"source":["!pip install face_recognition\n","!pip install opencv-python\n","!pip install dlib"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting face_recognition\n","  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.19.5)\n","Collecting face-recognition-models>=0.3.0\n","  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n","\u001b[K     |████████████████████████████████| 100.1 MB 25 kB/s \n","\u001b[?25hRequirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0)\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n","Building wheels for collected packages: face-recognition-models\n","  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566184 sha256=becc045e7ea75cb8c2e850ad1cfce44b21dc22761983c54c15b5f3a46a90a60f\n","  Stored in directory: /root/.cache/pip/wheels/d6/81/3c/884bcd5e1c120ff548d57c2ecc9ebf3281c9a6f7c0e7e7947a\n","Successfully built face-recognition-models\n","Installing collected packages: face-recognition-models, face-recognition\n","Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n","Requirement already satisfied: dlib in /usr/local/lib/python3.7/dist-packages (19.18.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4Bzgad5lKsPb","executionInfo":{"status":"ok","timestamp":1627298566113,"user_tz":-300,"elapsed":519,"user":{"displayName":"Afaq Saeed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gid4S9oyckVYLjntFyS9LKYBNOND0YkmrGkBqQ=s64","userId":"02893802679832682328"}}},"source":["from imutils import paths\n","import face_recognition\n","import pickle\n","import cv2\n","import os\n"," \n","#get paths of each file in folder named Images\n","#Images here contains my data(folders of various persons)\n","imagePaths = list(paths.list_images('/content/Images'))\n","knownEncodings = []\n","knownNames = []\n","# loop over the image paths\n","for (i, imagePath) in enumerate(imagePaths):\n","    # extract the person name from the image path\n","    name = imagePath.split(os.path.sep)[-2]\n","    # load the input image and convert it from BGR (OpenCV ordering)\n","    # to dlib ordering (RGB)\n","    image = cv2.imread(imagePath)\n","    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    #Use Face_recognition to locate faces\n","    boxes = face_recognition.face_locations(rgb,model='hog')\n","    # compute the facial embedding for the face\n","    encodings = face_recognition.face_encodings(rgb, boxes)\n","    # loop over the encodings\n","    for encoding in encodings:\n","        knownEncodings.append(encoding)\n","        knownNames.append(name)\n","#save emcodings along with their names in dictionary data\n","data = {\"encodings\": knownEncodings, \"names\": knownNames}\n","#use pickle to save data into a file for later use\n","f = open(\"face_enc\", \"wb\")\n","f.write(pickle.dumps(data))\n","f.close()"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":132},"id":"5VtjwG4ZLAJJ","executionInfo":{"status":"error","timestamp":1627298556381,"user_tz":-300,"elapsed":388,"user":{"displayName":"Afaq Saeed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gid4S9oyckVYLjntFyS9LKYBNOND0YkmrGkBqQ=s64","userId":"02893802679832682328"}},"outputId":"b7222ca6-a514-4c48-ca1f-c4f5015d6b86"},"source":["import face_recognition\n","import imutils\n","import pickle\n","import time\n","import cv2\n","import os\n"," \n","#find path of xml file containing haarcascade file \n","cascPathface = os.path.dirname(\n"," cv2.__file__) + \"/data/haarcascade_frontalface_alt2.xml\"\n","# load the harcaascade in the cascade classifier\n","faceCascade = cv2.CascadeClassifier(cascPathface)\n","# load the known faces and embeddings saved in last file\n","data = pickle.loads(open('face_enc', \"rb\").read())\n"," \n","print(\"Streaming started\")\n","video_capture = cv2.VideoCapture(0)\n","# loop over frames from the video file stream\n","while True:\n","    # grab the frame from the threaded video stream\n","    ret, frame = video_capture.read()\n","    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","    faces = faceCascade.detectMultiScale(gray,\n","                                         scaleFactor=1.1,\n","                                         minNeighbors=5,\n","                                         minSize=(60, 60),\n","                                         flags=cv2.CASCADE_SCALE_IMAGE)\n"," \n","    # convert the input frame from BGR to RGB \n","    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","    # the facial embeddings for face in input\n","    encodings = face_recognition.face_encodings(rgb)\n","    names = []\n","    # loop over the facial embeddings incase\n","    # we have multiple embeddings for multiple fcaes\n","    for encoding in encodings:\n","       #Compare encodings with encodings in data[\"encodings\"]\n","       #Matches contain array with boolean values and True for the embeddings it matches closely\n","       #and False for rest\n","        matches = face_recognition.compare_faces(data[\"encodings\"],\n","         encoding)\n","        #set name =inknown if no encoding matches\n","        name = \"Unknown\"\n","        # check to see if we have found a match\n","        if True in matches:\n","            #Find positions at which we get True and store them\n","            matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n","            counts = {}\n","            # loop over the matched indexes and maintain a count for\n","            # each recognized face face\n","            for i in matchedIdxs:\n","                #Check the names at respective indexes we stored in matchedIdxs\n","                name = data[\"names\"][i]\n","                #increase count for the name we got\n","                counts[name] = counts.get(name, 0) + 1\n","            #set name which has highest count\n","            name = max(counts, key=counts.get)\n"," \n"," \n","        # update the list of names\n","        names.append(name)\n","        # loop over the recognized faces\n","        for ((x, y, w, h), name) in zip(faces, names):\n","            # rescale the face coordinates\n","            # draw the predicted face name on the image\n","            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n","            cv2.putText(frame, name, (x, y), cv2.FONT_HERSHEY_SIMPLEX,\n","             0.75, (0, 255, 0), 2)\n","    cv2.imshow(\"Frame\", frame)\n","    if cv2.waitKey(1) &amp; 0xFF == ord('q'):\n","        break\n","video_capture.release()\n","cv2.destroyAllWindows()"],"execution_count":4,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-ede39230f451>\"\u001b[0;36m, line \u001b[0;32m70\u001b[0m\n\u001b[0;31m    if cv2.waitKey(1) &amp; 0xFF == ord('q'):\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]}]}