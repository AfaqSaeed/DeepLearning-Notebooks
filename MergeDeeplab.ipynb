{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"MergeDeeplab.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yBhwxczlPiEI","executionInfo":{"status":"ok","timestamp":1630928824850,"user_tz":-300,"elapsed":64646,"user":{"displayName":"MOAZ","photoUrl":"","userId":"13903430118672806542"}},"outputId":"80a0c0c0-4ada-42fd-8224-8110e5a19f70"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n"," \n","# Import PyDrive and associated libraries.\n","# This only needs to be done once per notebook.\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n"," \n","# Authenticate and create the PyDrive client.\n","# This only needs to be done once per notebook.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n"," \n","# Download the files based on its file ID.\n","# File-1\n"," \n","file_id1 = '1Z8lnKok5ufjVdBA-_f1UDmTkJoLqncqY'\n","module1 = drive.CreateFile({'id': file_id1})\n","module1.GetContentFile('datasets.py')\n"," \n","# File-2\n","file_id2 = '1wYVBj0dd7QcSfE4IH7Hk1rBZC562k_Ne'\n","module2 = drive.CreateFile({'id': file_id2})\n","module2.GetContentFile('deeplabv3.py')\n"," \n","# File-3\n","file_id3 = '1RB063J7lU1HZr8LVW55IKmw48Co_xBCO'\n","module3 = drive.CreateFile({'id': file_id3})\n","module3.GetContentFile('utils.py')\n"," \n","# File-4\n","file_id4 = '1_VxRsNJzUOYanJ48JgwcaWoJLtZSL85-'\n","module4 = drive.CreateFile({'id': file_id4})\n","module4.GetContentFile('resnet.py')\n"," \n","# File-5\n","file_id5 = '15gIBgRkR0DhdvxtTr7OMyGOiJ6W639IA'\n","module5 = drive.CreateFile({'id': file_id5})\n","module5.GetContentFile(\"aspp.py\")\n"," \n"," \n","print('Python files loaded')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","Python files loaded\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2kFBusT_Pxk2","executionInfo":{"status":"ok","timestamp":1630928831191,"user_tz":-300,"elapsed":4823,"user":{"displayName":"MOAZ","photoUrl":"","userId":"13903430118672806542"}},"outputId":"59c7aa9d-30e4-4e87-ca0e-bfb250a2258f"},"source":["import sys\n","import pandas\n","import torchvision\n","import torch\n","import torch.utils.data\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.models as models\n","\n","\n","import numpy as np\n","import cv2\n","import os\n","from google.colab import drive\n","import gc\n"," \n","os.sys.path.append('/content/gdrive/My Drive/deeplabv3/pytorch')\n","os.sys.path.append('/content/gdrive/My Drive/deeplabv3/pytorch/model')\n","os.sys.path.append('/content/gdrive/My Drive/deeplabv3/pytorch/utils')\n"," \n","import resnet\n","from resnet import ResNet18_OS16, ResNet34_OS16, ResNet50_OS16, ResNet101_OS16, ResNet152_OS16, ResNet18_OS8, ResNet34_OS8\n","from datasets import DatasetTrain, DatasetVal\n","from utils import add_weight_decay, MyModel\n","from deeplabv3 import DeepLabV3\n"," \n"," \n","\n","import time\n"," \n","print('Required Libraries Imported')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Required Libraries Imported\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RQi6naIXP1MX","executionInfo":{"status":"ok","timestamp":1630928846536,"user_tz":-300,"elapsed":15351,"user":{"displayName":"MOAZ","photoUrl":"","userId":"13903430118672806542"}},"outputId":"500d626c-db0f-4877-a5f4-df2cb9216325"},"source":["# We're unzipping the cuDNN files from your Drive folder directly to the VM CUDA folders\n","!tar -xzvf /content/gdrive/My\\ Drive/yolov3/darknet/cuDNN/cudnn-10.0-linux-x64-v7.5.0.56.tgz -C /usr/local/\n","!chmod a+r /usr/local/cuda/include/cudnn.h\n","\n","# Now we check the version we already installed. Can comment this line on future runs\n","!cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda/include/cudnn.h\n","cuda/NVIDIA_SLA_cuDNN_Support.txt\n","cuda/lib64/libcudnn.so\n","cuda/lib64/libcudnn.so.7\n","cuda/lib64/libcudnn.so.7.5.0\n","cuda/lib64/libcudnn_static.a\n","#define CUDNN_MAJOR 7\n","#define CUDNN_MINOR 5\n","#define CUDNN_PATCHLEVEL 0\n","--\n","#define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\n","\n","#include \"driver_types.h\"\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dXAoN0jVP3Gr","executionInfo":{"status":"ok","timestamp":1630928846536,"user_tz":-300,"elapsed":10,"user":{"displayName":"MOAZ","photoUrl":"","userId":"13903430118672806542"}},"outputId":"fb9b3de7-9d6f-474d-90be-630864fbd841"},"source":["# NOTE! NOTE! change this to not overwrite all log data when you train the model:\n","model_id = \"4\"\n","\n","num_epochs = 300\n","batch_size = 8\n","learning_rate = 0.0001\n","base_lr=0.0001/500\n","max_lr=0.0001\n","cuda = True if torch.cuda.is_available() else False\n","\n","print('Hyperparameters set')\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hyperparameters set\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ISZwXNDbP8q0","executionInfo":{"status":"ok","timestamp":1630928848096,"user_tz":-300,"elapsed":1564,"user":{"displayName":"MOAZ","photoUrl":"","userId":"13903430118672806542"}},"outputId":"6c8609e3-6fad-4944-b5c7-ce2cbd44376a"},"source":["proj_dir = \"/content/gdrive/My Drive/deeplabv3/pytorch/\"\n","\n","network = DeepLabV3(model_id, project_dir = proj_dir,num_classes=8)\n","\n","# train_dataset = DatasetTrain(data_path = proj_dir + \"data/train/\",\n","#                              label_path = proj_dir + \"data/labels/\",enabletransform=True)\n","# val_dataset = DatasetVal(data_path = proj_dir + \"data/val/\",\n","#                          label_path = proj_dir + \"data/labels/\")\n","\n","\n","# num_train_batches = int(len(train_dataset)/batch_size)\n","# num_val_batches = int(len(val_dataset)/batch_size)\n","# print (\"num_train_batches:\", num_train_batches)\n","# print (\"num_val_batches:\", num_val_batches)\n","\n","# train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","#                                            batch_size=batch_size, shuffle=True,\n","#                                            num_workers=2,pin_memory=True, drop_last=True)\n","# val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n","#                                          batch_size=batch_size, shuffle=False,\n","#                                          num_workers=2,pin_memory=True, drop_last=True)\n","# l=len(os.listdir(proj_dir+\"training_logs/model_\"+model_id+\"/checkpoints\"))\n","\n","# #print(os.listdir(proj_dir+\"training_logs/model_\"+model_id+\"/checkpoints\")[-1])\n","# params = add_weight_decay(network, l2_value=0.0001)\n","# optimizer = torch.optim.Adam(params, lr=learning_rate)\n","# # Code for Learning rate schedulers \n","# #scheduler=torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr, max_lr, step_size_up=320, step_size_down=None, mode='triangular2', gamma=1.0, scale_fn=None, scale_mode='cycle', cycle_momentum=False, base_momentum=0.8, max_momentum=0.9, last_epoch=-1, verbose=False)\n","\n","# #Random code that has been in the notebook from the start \n","# #with open(\"/content/gdrive/My Drive/StradaImaging/deeplabv3_pytorch/data/cityscapes/meta/class_weights.pkl\", \"rb\") as file: # (needed for python3)\n","# #    class_weights = np.array(pickle.load(file))\n","# #class_weights = torch.from_numpy(class_weights)\n","# #class_weights = Variable(class_weights.type(torch.FloatTensor))#.cuda()\n","\n","# # loss function\n","# loss_fn = nn.CrossEntropyLoss()#weight=class_weights)\n","# #loss_fn = nn.MSELoss()\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["pretrained resnet, 18<3\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OHcI_Fr0P_IR","executionInfo":{"status":"ok","timestamp":1630928867062,"user_tz":-300,"elapsed":18970,"user":{"displayName":"MOAZ","photoUrl":"","userId":"13903430118672806542"}},"outputId":"94de6e77-932f-421d-84a8-86efb5224326"},"source":["new_weights_path = proj_dir+\"training_logs/model_\"+model_id+\"/checkpoints/\"+os.listdir(proj_dir+\"training_logs/model_\"+model_id+\"/checkpoints\")[-1] # start training from last saved weights\n","new_state_dict=torch.load(new_weights_path,map_location=\"cuda\")\n","city_weights=proj_dir+\"pretrained_models/model_13_2_2_2_epoch_580.pth\" # start training from orignal pretrained model\n","city_state_dict=torch.load(city_weights,map_location=\"cuda\")\n","network = MyModel(network, model_id, proj_dir)\n","#network.cuda()\n","network.load_state_dict(new_state_dict)\n","\n","print(new_weights_path)\n","device = torch.device(\"cuda\")\n","network.to(device)\n","\n","# re define model\n","\n","\n","# Define tensor types\n","Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n","LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/deeplabv3/pytorch/training_logs/model_4/checkpoints/model_4_epoch_230.pth\n"]}]},{"cell_type":"code","metadata":{"id":"D31xzCBwPu_v"},"source":["def label_img_to_color(img):\n","    img=img.astype(np.uint8)\n","    lut=np.ones((256,1,3),dtype=np.uint8)\n","    \n","    ine=np.array([[[0,0,0],#background 0\n","                   [255,0,0],#signboard blue 1 \n","                   [0,255,0],#siderail green  2\n","                   [0,0,255],#sidewall red 3\n","                   [49,147,245],#traffic cone orange 4\n","                   [255,255,0],#markerposts cyan 5\n","                   [255,0,255],#trafficbarrier magenta 6\n","                   [0,0,255],#manhole yellow 7\n","                   [255,255, 255],#road white 8\n","                   [ 79,79,47],#sidewalk gray 9\n","                   [0,128,128],#pole slate olive 10 \n","                   [19, 69, 139],]])#fence brown 11\n","    \n","    lut[0:12,:,:]=ine.reshape(12,1,3)\n","    img_color=cv2.applyColorMap(img,lut)\n","\n","    return img_color"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ZmV8SS5W_nz","executionInfo":{"status":"ok","timestamp":1630929490830,"user_tz":-300,"elapsed":135059,"user":{"displayName":"MOAZ","photoUrl":"","userId":"13903430118672806542"}},"outputId":"abe17023-22e4-4669-eddc-ab7cb174511a"},"source":["from google.colab.patches import cv2_imshow # Debugging Import\n","\n","dir=proj_dir+\"data/val/\"\n","paths=os.listdir(dir)\n","for i,img_path in enumerate(paths):\n","        \n","        #Defining the 8 class network  \n","        \n","        network = DeepLabV3(model_id, project_dir = proj_dir,num_classes=8)\n","        network = MyModel(network, model_id, proj_dir)\n","        network.cuda()\n","        network.load_state_dict(new_state_dict)\n","        device = torch.device(\"cuda\")                 #change device on which to perform computations replace cuda with cpu if you want to run on that\n","        network.to(device)\n","        Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n","        LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor\n","        \n","        network.eval() #Set to Inference i.e evaluation or detection mode\n","\n","        with torch.no_grad(): # (This is done to reduce memory consumption)\n","       \n","          print(img_path)\n","          \n","          #Preprocess the image to resemble the transformation done while loading the images in datasetloafer function( Datasets.py File )\n","         \n","          img = cv2.imread(dir+img_path, -1) # (shape: (1024, 2048, 3))\n","          oimg = cv2.resize(img, (1024,512), interpolation=cv2.INTER_NEAREST)\n","          img = oimg/255.0\n","          img = img - np.array([0.485, 0.456, 0.406])\n","          img = img/np.array([0.229, 0.224, 0.225]) # (shape: (512, 1024, 3))\n","          img = np.transpose(img, (2, 0, 1)) # (shape: (3, 512, 1024))\n","          img = img.astype(np.float32)\n","          img = torch.from_numpy(img)\n","          img_batch=torch.unsqueeze(img,0)\n","          img_batch = Variable(img_batch).cuda()\n","         \n","          #Perform inference on 8 class network\n","         \n","          output1 = network(img_batch) # (shape: (batch_size, num_classes, img_h, img_w))\n","          \n","          \n","          _, predicted = torch.max(output1.data, 1)\n","          output1 = output1.data.cpu().numpy() # (shape: (batch_size, num_classes, img_h, img_w))\n","          pred_label_imgs = np.argmax(output1, axis=1) # (shape: (batch_size, img_h, img_w))\n","          pred_label_imgs = pred_label_imgs.astype(np.uint8)\n","          pred1 = pred_label_imgs[0].astype(np.uint8)        \n","\n","          #Define the second 20 class network\n","          \n","          network = DeepLabV3(model_id, project_dir = proj_dir,num_classes=20)\n","          network.load_state_dict(city_state_dict) \n","          network.cuda()\n","          network.eval()\n","          output2=network(img_batch)\n","            \n","          _, predicted = torch.max(output2.data, 1)\n","          output2=output2.data.cpu().numpy()\n","          PRED= np.argmax(output2,axis=1)\n","          PRED= PRED.astype(np.uint8)    \n","          pred2=PRED[0]\n","\n","          # Applying Threshold to detect gray area and create a mask \n","          lower_gray = np.array([150,0,20])\n","          upper_gray = np.array([180,20,255])\n","          hsv=cv2.cvtColor(oimg,cv2.COLOR_BGR2HSV)\n","          mask=cv2.inRange(hsv, lower_gray, upper_gray)\n","          \n","          #Create a mask that selects only lower third portion of the image\n","          \n","          h,l=pred1.shape[0],pred1.shape[1]\n","          a_mask=np.zeros((pred1.shape),dtype=bool)\n","          a_mask[h-int(h/3):h]=True\n","          mask=np.bitwise_and(a_mask,mask)\n","          # Merge labels from cityscapes onto our 8 class network to produce 12 class labelss\n","        \n","          pred1=np.where(np.bitwise_and(pred2>6 ,mask),8,pred1)\n","          pred1=np.where(pred2==0,8,pred1)\n","          pred1=np.where(pred2==1,9,pred1)\n","          pred1=np.where(pred2==5,10,pred1)\n","          pred1=np.where(pred2==4,11,pred1)\n","          cv2.imwrite(proj_dir+\"/data/Combined/\"+img_path[:-3]+\"png\",pred1)\n","          net_img=label_img_to_color(pred1)\n","          city_img=label_img_to_color(pred2)\n","          city_img=city_img*0.35+oimg*0.65\n","          net_img=net_img*0.35+oimg*0.65\n","          total=np.concatenate((city_img,net_img),1)\n","          total=cv2.resize(total,(1024,512),interpolation=cv2.INTER_NEAREST)    "],"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1048.jpg\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3487: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n","  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3613: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode)\n"]},{"output_type":"stream","name":"stdout","text":["pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1054.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1060.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1068.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1132.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1142.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1144.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1150.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1174.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1216.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1218.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1220.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1236.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1238.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1254.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1278.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1282.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1296.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1308.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1358.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1370.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1380.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1382.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1416.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1422.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1452.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1494.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1528.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1536.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1538.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1614.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1624.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1680.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1696.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1734.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1758.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1772.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1778.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1836.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1846.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1864.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1884.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1894.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1908.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1920.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1932.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1934.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1942.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1972.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1980.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_1994.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2024.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2036.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2056.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2074.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2088.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2146.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2180.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2186.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2188.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2220.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2234.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2244.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2248.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2256.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2268.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2308.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2318.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2320.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2332.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2358.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2362.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2398.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2410.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2444.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2470.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2482.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_0950.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_0750.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_0514.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_0452.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_0590.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_0720.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_0646.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_0928.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_0712.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_0586.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_0662.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_0840.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_0962.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_0854.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_0938.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_0584.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_0904.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_0494.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_0902.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_0566.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_0918.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_0680.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3166.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2806.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3054.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3196.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2664.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3478.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3484.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2516.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3168.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2800.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3252.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3418.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3002.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3310.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2662.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3386.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2722.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2860.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3118.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3030.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3292.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3304.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3066.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3334.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2580.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3106.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3074.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3042.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2628.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2720.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3130.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3486.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2536.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2612.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2916.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3142.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2724.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3480.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3368.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3096.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2898.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3266.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3306.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2658.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3466.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2518.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2606.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2588.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3154.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2936.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3192.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2550.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2554.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3402.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3230.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2924.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3014.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3356.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2576.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3048.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2782.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2682.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3474.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2894.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2888.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2774.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2526.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2656.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2864.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2718.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3410.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3280.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2764.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3076.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3396.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2826.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2694.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3190.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2962.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3050.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3448.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3442.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3348.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2896.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2846.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3344.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3214.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2780.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2994.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2648.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2512.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2760.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3152.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2556.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2572.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3412.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2558.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3308.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_2972.jpg\n","pretrained resnet, 18<3\n","pretrained resnet, 18<3\n","M1 J23a Slips_Forward_3354.jpg\n","pretrained resnet, 18<3\n"]}]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1qOXu1Vh18JbNAO-iLA85JUT0eMAQf4Qe"},"id":"JJoRkQOt5tIw","outputId":"9e7e2ef7-78ba-4b9f-940d-01bd1027ea12"},"source":["import shutil\n","import random \n","copy_path=proj_dir+\"data/val/\"\n","other=proj_dir+\"data/train/\"\n","labels=proj_dir+\"data/Combined/\"\n","paths=random.sample(os.listdir(dir),100)\n","for img in paths:\n","  oimg=cv2.imread(dir+img)\n","  oimg=cv2.resize(oimg,(1024,512),interpolation=cv2.INTER_NEAREST)\n","  label=cv2.imread(labels+img[:-3]+\"png\")\n","  print(labels+img)\n","  net_img=label_img_to_color(label)\n","  net_img=net_img*0.35+oimg*0.65\n","  cv2_imshow(net_img)\n","  "],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1pvzTlhqR-04dPji8j4cUvjK8I-PxpbmH"},"id":"tO0NTmWDOPSG","executionInfo":{"elapsed":33353,"status":"ok","timestamp":1630741976383,"user":{"displayName":"Afaq Saeed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gid4S9oyckVYLjntFyS9LKYBNOND0YkmrGkBqQ=s64","userId":"02893802679832682328"},"user_tz":-300},"outputId":"e0f10ec4-11c3-4035-81db-cab7148e2a41"},"source":["\n","import sys                                          # System bindings\n","import cv2                                          # OpenCV bindings\n","import numpy as np\n","\n","\n","class ColorAnalyser():\n","    def __init__(self, imageLoc):\n","        \n","        img= cv2.imread(imageLoc, 1)\n","        cv2_imshow(img)\n","        blur= cv2.medianBlur(img,255)\n","        cv2_imshow(blur)\n","        self.src=blur#cv2.cvtColor(blur,cv2.COLOR_BGR2HSV)\n","        \n","               # Reads in image source\n","        # Empty dictionary container to hold the colour frequencies\n","        self.colors_count = {}\n","        self.height=img.shape[0]\n","        self.width=img.shape[1]\n","        self.area=self.height*self.width\n","    def count_colors(self):\n","        # Splits image Mat into 3 color channels in individual 2D arrays\n","        (channel_b, channel_g, channel_r) = cv2.split(self.src)\n","\n","        # Flattens the 2D single channel array so as to make it easier to iterate over it\n","        channel_b = channel_b.flatten()\n","        channel_g = channel_g.flatten()  # \"\"\n","        channel_r = channel_r.flatten()  # \"\"\n","\n","        for i in range(len(channel_b)):\n","            HSV = \"(\" + str(channel_r[i]) + \",\" + \\\n","                str(channel_g[i]) + \",\" + str(channel_b[i]) + \")\"\n","            #print(channel_b[i])\n","            if HSV in self.colors_count:\n","                self.colors_count[HSV] += 1\n","            else:\n","                self.colors_count[HSV] = 1\n","\n","        print(\"Colours counted\")\n","\n","    def show_colors(self):\n","        # Sorts dictionary by value\n","        print(\"Top 2colors percentages\")\n","        for i,keys in enumerate(sorted(self.colors_count, key=self.colors_count.__getitem__)):\n","            # Prints 'key: value'\n","            if (len(self.colors_count)-i)<3:\n","              \n","              print(keys, \": \", (self.colors_count[keys]/self.area)*100)\n","\n","    def main(self):\n","        # Checks if an image was actually loaded and errors if it wasn't\n","        if (self.src is None):\n","            print(\"No image data. Check image location for typos\")\n","        else:\n","            # Counts the amount of instances of HSV values within the image\n","            self.count_colors()\n","            # Sorts and shows the colors ordered from least to most often occurance\n","            self.show_colors()\n","            # Waits for kegiven as cli argument\n","Analyser = ColorAnalyser(\"/content/gdrive/MyDrive/deeplabv3/annotation_images/M1 J23a Slips_Forward_1001.jpg\")\n","Analyser.main()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":547,"output_embedded_package_id":"1OO1_SW2C0Cjk1TlvE2_kkfKRPYRg44rR"},"id":"q_d8Cn4m38tT","executionInfo":{"elapsed":12900,"status":"ok","timestamp":1630751145278,"user":{"displayName":"Afaq Saeed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gid4S9oyckVYLjntFyS9LKYBNOND0YkmrGkBqQ=s64","userId":"02893802679832682328"},"user_tz":-300},"outputId":"f2d5516f-8bd7-48df-f807-953fca8e75d4"},"source":["img=cv2.imread(\"/content/gdrive/MyDrive/deeplabv3/annotation_images/M1 J23a Slips_Forward_1001.jpg\")\n","#(b,g,r)=cv2.split(img)\n","hsv=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n","#print(b.shape)\n","# c=1\n","# print(np.unique(im))\n","lower_gray = np.array([0,0,20])\n","upper_gray = np.array([180,20,200])\n","slices=cv2.inRange(hsv,lower_gray,upper_gray)\n","# slices=np.zeros(img.shape)\n","# bg = np.bitwise_and(((im[:,:,0]-im[:,:,1])<c),((im[:,:,0]-im[:,:,1])>(-1*c)),dtype=np.uint8) # B == G\n","# gr = np.bitwise_and(((im[:,:,1]-im[:,:,2])<c),((im[:,:,1]-im[:,:,2])>(-1*c)),dtype=np.uint8) \n","# slices[:,:,0] = np.bitwise_and(bg, gr, dtype= np.uint8)*  img[:,:,0]\n","# slices[:,:,1] = np.bitwise_and(bg, gr, dtype= np.uint8)*  img[:,:,1]\n","# slices[:,:,2] = np.bitwise_and(bg, gr, dtype= np.uint8)*  img[:,:,2]\n","# gray=(np.isclose(b>100,g<150,c))#&np.isclose(g,r,c)&np.isclose(b,r,c))\n","# gray=np.reshape(gray,(b.shape))\n","# print(gray.shape)\n","#cv2_imshow(img)\n","cv2_imshow(cv2.bitwise_and(img,img, mask= slices))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"U7AtoxdpDN6-"},"source":[""],"execution_count":null,"outputs":[]}]}